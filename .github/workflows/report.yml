name: Benchmark and Performance Report

on:
  workflow_dispatch: # Allow manual triggering
    inputs:
      tag_name:
        description: 'Tag to benchmark (optional, defaults to latest)'
        required: false
        type: string
  workflow_call: # Allow calling from other workflows
    inputs:
      tag_name:
        description: 'Tag to benchmark'
        required: false
        type: string
  release:
    types: [published] # Run when a release is published

# Security: Minimal required permissions
permissions:
  contents: write       # Update release notes
  actions: write        # Upload artifacts
  
# Prevent concurrent benchmark runs
concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: false

jobs:
  benchmark:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Determine target tag/ref
        id: determine_target
        run: |
          if [[ "${{ github.event_name }}" == "release" ]]; then
            TAG_NAME="${{ github.event.release.tag_name }}"
            echo "Using release tag: $TAG_NAME"
          elif [[ -n "${{ inputs.tag_name }}" ]]; then
            TAG_NAME="${{ inputs.tag_name }}"
            echo "Using input tag: $TAG_NAME"
          else
            # Get latest tag
            git fetch --tags
            TAG_NAME=$(git describe --tags $(git rev-list --tags --max-count=1) 2>/dev/null || echo "main")
            echo "Using latest tag: $TAG_NAME"
          fi
          
          echo "target_ref=$TAG_NAME" >> $GITHUB_OUTPUT
          echo "tag_name=$TAG_NAME" >> $GITHUB_ENV
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.determine_target.outputs.target_ref }}
          fetch-depth: 0
      
      - name: Check if benchmark already exists
        id: check_benchmark
        if: github.event_name == 'release'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RELEASE_BODY=$(gh release view "${{ env.tag_name }}" --json body --jq '.body')
          if [[ $RELEASE_BODY == *"Performance Report"* ]]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è Benchmark already exists for this release"
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "‚úÖ No benchmark found, will run"
          fi
      
      - name: Setup .NET
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: |
            ${{ vars.DOTNET_VERSION || '8.0.x' }}
            8.0.x
            6.0.x
            2.1.x
      
      
      - name: Cache NuGet packages
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-benchmark-${{ hashFiles('**/*.csproj') }}
      
      - name: Restore dependencies
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: dotnet restore
      
      - name: Build benchmark project
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: |
          cd Nino.Benchmark
          dotnet build -c Release
      
      - name: Run benchmarks
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: |
          cd Nino.Benchmark
          echo "Running benchmarks for ${{ env.tag_name }}..."
          dotnet run -c Release --no-build
          
          # Verify benchmark results exist (we're in src/Nino.Benchmark directory)
          if [[ -f "BenchmarkDotNet.Artifacts/results/Nino.Benchmark.SimpleTest-report-github.md" ]]; then
            echo "‚úÖ Benchmark completed successfully"
          else
            echo "‚ùå Benchmark results not found in $(pwd)"
            echo "Looking for: BenchmarkDotNet.Artifacts/results/Nino.Benchmark.SimpleTest-report-github.md"
            echo "Available files in results directory:"
            if [[ -d "BenchmarkDotNet.Artifacts/results/" ]]; then
              ls -la BenchmarkDotNet.Artifacts/results/
            else
              echo "‚ùå Results directory BenchmarkDotNet.Artifacts/results/ not found"
              echo "Available in BenchmarkDotNet.Artifacts/:"
              ls -la BenchmarkDotNet.Artifacts/ || echo "BenchmarkDotNet.Artifacts directory not found"
            fi
            exit 1
          fi
      
      - name: Upload benchmark artifacts
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ env.tag_name }}
          path: |
            src/Nino.Benchmark/**/BenchmarkDotNet.Artifacts/results
          retention-days: 90
      
      
      - name: Update release notes with benchmark
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          
          TAG_NAME="${{ env.tag_name }}"
          
          # Find the generated markdown file (BenchmarkDotNet generates various filename patterns)
          echo "üîç Looking for benchmark markdown files..."
          
          # Look for any markdown file in results using wildcard search
          BENCHMARK_FILE=$(find Nino.Benchmark -path "*/BenchmarkDotNet.Artifacts/results/*.md" -type f | head -n1)
          
          if [[ -z "$BENCHMARK_FILE" || ! -f "$BENCHMARK_FILE" ]]; then
            echo "‚ùå No markdown benchmark report found in BenchmarkDotNet artifacts"
            echo "Available benchmark directories:"
            find Nino.Benchmark -name "BenchmarkDotNet.Artifacts" -type d
            exit 1
          fi
          
          echo "‚úÖ Found benchmark report: $BENCHMARK_FILE"
          
          # Read benchmark content
          PERF_CONTENT=$(cat "$BENCHMARK_FILE")
          
          
          # Get current release body
          RELEASE_BODY=$(gh release view "$TAG_NAME" --json body --jq '.body')
          
          # Check if benchmark already exists in release notes
          if [[ $RELEASE_BODY == *"Performance Report"* ]]; then
            echo "‚è≠Ô∏è Benchmark already exists in release notes"
            exit 0
          fi
          
          # Create updated release notes with better formatting
          {
            echo "$RELEASE_BODY"
            echo ""
            echo "## üìä Performance Report"
            echo ""
            echo "<details>"
            echo "<summary>Click to expand benchmark results</summary>"
            echo ""
            cat "$BENCHMARK_FILE"
            echo ""
            echo "</details>"
            echo ""
            echo "---"
            echo "*Benchmark generated automatically on $(date -u '+%Y-%m-%d %H:%M:%S UTC')*"
          } > updated_notes.md
          
          # Update the release
          gh release edit "$TAG_NAME" --notes-file updated_notes.md
          echo "‚úÖ Release notes updated with benchmark results"
      
      - name: Benchmark summary
        if: steps.check_benchmark.outputs.skip != 'true'
        run: |
          echo "## üìä Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Target**: ${{ env.tag_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ‚úÖ Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Results**: Uploaded as artifacts" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ github.event_name }}" == "release" ]]; then
            echo "- **Release Notes**: Updated automatically" >> $GITHUB_STEP_SUMMARY
          fi
