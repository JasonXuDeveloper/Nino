name: Benchmark and Performance Report

on:
  workflow_dispatch: # Allow manual triggering
    inputs:
      tag_name:
        description: 'Tag to benchmark (optional, defaults to latest)'
        required: false
        type: string
  workflow_call: # Allow calling from other workflows
    inputs:
      tag_name:
        description: 'Tag to benchmark'
        required: false
        type: string
  release:
    types: [published] # Run when a release is published

# Security: Minimal required permissions
permissions:
  contents: write       # Update release notes
  actions: write        # Upload artifacts
  
# Prevent concurrent benchmark runs
concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: false

jobs:
  benchmark:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Determine target tag/ref
        id: determine_target
        run: |
          if [[ "${{ github.event_name }}" == "release" ]]; then
            TAG_NAME="${{ github.event.release.tag_name }}"
            echo "Using release tag: $TAG_NAME"
          elif [[ -n "${{ inputs.tag_name }}" ]]; then
            TAG_NAME="${{ inputs.tag_name }}"
            echo "Using input tag: $TAG_NAME"
          else
            # Get latest tag
            git fetch --tags
            TAG_NAME=$(git describe --tags $(git rev-list --tags --max-count=1) 2>/dev/null || echo "main")
            echo "Using latest tag: $TAG_NAME"
          fi
          
          echo "target_ref=$TAG_NAME" >> $GITHUB_OUTPUT
          echo "tag_name=$TAG_NAME" >> $GITHUB_ENV
      
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.determine_target.outputs.target_ref }}
          fetch-depth: 0
      
      - name: Check if benchmark already exists
        id: check_benchmark
        if: github.event_name == 'release'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RELEASE_BODY=$(gh release view "${{ env.tag_name }}" --json body --jq '.body')
          if [[ $RELEASE_BODY == *"Performance Report"* ]]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "â­ï¸ Benchmark already exists for this release"
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "âœ… No benchmark found, will run"
          fi
      
      - name: Setup .NET
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: |
            ${{ vars.DOTNET_VERSION || '8.0.x' }}
            8.0.x
            6.0.x
            2.1.x
      
      - name: Setup R for benchmark plots
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3.2'
        continue-on-error: true
        id: setup_r
      
      - name: Cache R packages
        if: steps.check_benchmark.outputs.skip != 'true' && steps.setup_r.outcome == 'success'
        uses: actions/cache@v4
        with:
          path: ~/.local/share/renv
          key: ${{ runner.os }}-renv-${{ hashFiles('**/.Rprofile') }}
          restore-keys: |
            ${{ runner.os }}-renv-
      
      - name: Install R dependencies for plots
        if: steps.check_benchmark.outputs.skip != 'true' && steps.setup_r.outcome == 'success'
        run: |
          # Install required R packages for BenchmarkDotNet plots
          Rscript -e "
            if (!require('ggplot2', quietly = TRUE)) install.packages('ggplot2', repos = 'https://cran.rstudio.com/')
            if (!require('dplyr', quietly = TRUE)) install.packages('dplyr', repos = 'https://cran.rstudio.com/')
            if (!require('plotly', quietly = TRUE)) install.packages('plotly', repos = 'https://cran.rstudio.com/')
            cat('R packages installed successfully\n')
          "
        continue-on-error: true
        id: install_r_packages
      
      - name: Cache NuGet packages
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-benchmark-${{ hashFiles('**/*.csproj') }}
      
      - name: Restore dependencies
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: dotnet restore
      
      - name: Build benchmark project
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: |
          cd Nino.Benchmark
          dotnet build -c Release
      
      - name: Run benchmarks
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        run: |
          cd Nino.Benchmark
          echo "Running benchmarks for ${{ env.tag_name }}..."
          
          # Check R environment status
          if [[ "${{ steps.setup_r.outcome }}" == "success" && "${{ steps.install_r_packages.outcome }}" == "success" ]]; then
            echo "âœ… R environment available - plots will be generated"
          else
            echo "âš ï¸ R environment not available - continuing without plots"
          fi
          
          dotnet run -c Release --no-build
          
          # Verify benchmark results exist (we're in src/Nino.Benchmark directory)
          if [[ -f "BenchmarkDotNet.Artifacts/results/Nino.Benchmark.SimpleTest-report-github.md" ]]; then
            echo "âœ… Benchmark completed successfully"
          else
            echo "âŒ Benchmark results not found in $(pwd)"
            echo "Looking for: BenchmarkDotNet.Artifacts/results/Nino.Benchmark.SimpleTest-report-github.md"
            echo "Available files in results directory:"
            if [[ -d "BenchmarkDotNet.Artifacts/results/" ]]; then
              ls -la BenchmarkDotNet.Artifacts/results/
            else
              echo "âŒ Results directory BenchmarkDotNet.Artifacts/results/ not found"
              echo "Available in BenchmarkDotNet.Artifacts/:"
              ls -la BenchmarkDotNet.Artifacts/ || echo "BenchmarkDotNet.Artifacts directory not found"
            fi
            exit 1
          fi
      
      - name: Upload benchmark artifacts
        if: steps.check_benchmark.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ env.tag_name }}
          path: |
            src/Nino.Benchmark/**/BenchmarkDotNet.Artifacts/results
          retention-days: 90
      
      - name: Upload benchmark plots to release
        if: steps.check_benchmark.outputs.skip != 'true' && steps.setup_r.outcome == 'success' && steps.install_r_packages.outcome == 'success'
        working-directory: ./src
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          
          TAG_NAME="${{ env.tag_name }}"
          
          echo "ðŸ” Looking for R plot images in BenchmarkDotNet artifacts..."
          
          # Find PNG files generated by RPlotExporter using wildcard search
          PNG_FILES=$(find Nino.Benchmark -path "*/BenchmarkDotNet.Artifacts/results/*.png" -type f 2>/dev/null)
          
          if [[ -n "$PNG_FILES" ]]; then
            PNG_COUNT=$(echo "$PNG_FILES" | wc -l)
            echo "âœ… Found $PNG_COUNT plot images, uploading to release..."
            
            echo "$PNG_FILES" | while IFS= read -r plot_file; do
              if [[ -n "$plot_file" ]]; then
                plot_name=$(basename "$plot_file")
                echo "ðŸ“ˆ Uploading: $plot_name"
                gh release upload "$TAG_NAME" "$plot_file" --clobber || echo "âš ï¸ Failed to upload $plot_name"
              fi
            done
            
            echo "plot_images_uploaded=true" >> $GITHUB_OUTPUT
          else
            echo "â„¹ï¸ No plot images found"
            echo "Available BenchmarkDotNet directories:"
            find Nino.Benchmark -name "BenchmarkDotNet.Artifacts" -type d 2>/dev/null || echo "No BenchmarkDotNet.Artifacts directories found"
            echo "plot_images_uploaded=false" >> $GITHUB_OUTPUT
          fi
        id: upload_plots
      
      - name: Update release notes with benchmark
        if: steps.check_benchmark.outputs.skip != 'true'
        working-directory: ./src
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          
          TAG_NAME="${{ env.tag_name }}"
          
          # Find the generated markdown file (BenchmarkDotNet generates various filename patterns)
          echo "ðŸ” Looking for benchmark markdown files..."
          
          # Look for any markdown file in results using wildcard search
          BENCHMARK_FILE=$(find Nino.Benchmark -path "*/BenchmarkDotNet.Artifacts/results/*.md" -type f | head -n1)
          
          if [[ -z "$BENCHMARK_FILE" || ! -f "$BENCHMARK_FILE" ]]; then
            echo "âŒ No markdown benchmark report found in BenchmarkDotNet artifacts"
            echo "Available benchmark directories:"
            find Nino.Benchmark -name "BenchmarkDotNet.Artifacts" -type d
            exit 1
          fi
          
          echo "âœ… Found benchmark report: $BENCHMARK_FILE"
          
          # Read benchmark content
          PERF_CONTENT=$(cat "$BENCHMARK_FILE")
          
          # Build plot images markdown if they were uploaded
          PLOT_IMAGES=""
          if [[ "${{ steps.upload_plots.outputs.plot_images_uploaded }}" == "true" ]]; then
            echo "ðŸ“ˆ Building plot images section..."
            
            # Create plot images markdown
            PLOT_IMAGES=""
            PNG_FILES_FOR_MARKDOWN=$(find Nino.Benchmark -path "*/BenchmarkDotNet.Artifacts/results/*.png" -type f 2>/dev/null)
            
            if [[ -n "$PNG_FILES_FOR_MARKDOWN" ]]; then
              while IFS= read -r plot_file; do
                if [[ -n "$plot_file" ]]; then
                  plot_name=$(basename "$plot_file")
                  plot_title="${plot_name%.*}"
                  if [[ -z "$PLOT_IMAGES" ]]; then
                    PLOT_IMAGES="![${plot_title}](https://github.com/${{ github.repository }}/releases/download/$TAG_NAME/$plot_name)"
                  else
                    PLOT_IMAGES="${PLOT_IMAGES}"$'\n'"![${plot_title}](https://github.com/${{ github.repository }}/releases/download/$TAG_NAME/$plot_name)"
                  fi
                fi
              done <<< "$PNG_FILES_FOR_MARKDOWN"
            fi
            
            echo "âœ… Plot images markdown created"
          else
            echo "â„¹ï¸ No plot images to include"
          fi
          
          # Get current release body
          RELEASE_BODY=$(gh release view "$TAG_NAME" --json body --jq '.body')
          
          # Check if benchmark already exists in release notes
          if [[ $RELEASE_BODY == *"Performance Report"* ]]; then
            echo "â­ï¸ Benchmark already exists in release notes"
            exit 0
          fi
          
          # Create updated release notes with better formatting
          {
            echo "$RELEASE_BODY"
            echo ""
            echo "## ðŸ“Š Performance Report"
            echo ""
            echo "<details>"
            echo "<summary>Click to expand benchmark results</summary>"
            echo ""
            cat "$BENCHMARK_FILE"
            echo ""
            echo "</details>"
            
            # Add plot images if available
            if [[ -n "$PLOT_IMAGES" ]]; then
              echo ""
              echo "<details>"
              echo "<summary>ðŸ“ˆ Click to expand performance charts</summary>"
              echo ""
              echo "$PLOT_IMAGES"
              echo ""
              echo "</details>"
            fi
            echo ""
            echo "---"
            echo "*Benchmark generated automatically on $(date -u '+%Y-%m-%d %H:%M:%S UTC')*"
          } > updated_notes.md
          
          # Update the release
          gh release edit "$TAG_NAME" --notes-file updated_notes.md
          echo "âœ… Release notes updated with benchmark results"
      
      - name: Benchmark summary
        if: steps.check_benchmark.outputs.skip != 'true'
        run: |
          echo "## ðŸ“Š Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Target**: ${{ env.tag_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Results**: Uploaded as artifacts" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ github.event_name }}" == "release" ]]; then
            echo "- **Release Notes**: Updated automatically" >> $GITHUB_STEP_SUMMARY
          fi
